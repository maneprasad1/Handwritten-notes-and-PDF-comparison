{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8022bd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.8062492\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compare_answers(student_answer, ideal_answer):\n",
    "    # Load the BERT-based model\n",
    "    model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "    # Encode student and ideal answers into embeddings\n",
    "    student_embedding = model.encode([student_answer])\n",
    "    ideal_embedding = model.encode([ideal_answer])\n",
    "\n",
    "    # Compute the cosine similarity between the embeddings\n",
    "    similarity = cosine_similarity(student_embedding, ideal_embedding)[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Example usage\n",
    "student_answer = \"THE black fox slides below dog fast.\"\n",
    "ideal_answer = \"The brown fox jumps over the lazy dog quickly.\"\n",
    "similarity_score = compare_answers(student_answer, ideal_answer)\n",
    "print(\"Similarity score:\", similarity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a3a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c858d9f8",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2780435d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18596\\3474899674.py\", line 58, in compare\n",
      "    similarity_score = compare_notes(notes1, notes2)\n",
      "NameError: name 'compare_notes' is not defined\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import ttk\n",
    "import PyPDF2\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into individual words\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Convert to lowercase\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    # Remove stopwords and punctuation\n",
    "    stopwords_set = set(stopwords.words(\"english\"))\n",
    "    tokens = [token for token in tokens if token.isalnum() and token not in stopwords_set]\n",
    "    # Join the tokens back into a single string\n",
    "    preprocessed_text = \" \".join(tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "def compare_answers(student_answer, ideal_answer):\n",
    "    # Preprocess the student and ideal answers\n",
    "    notes1 = preprocess_text(student_answer)\n",
    "    notes2 = preprocess_text(ideal_answer)\n",
    "\n",
    "    # Create a TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    # Fit the vectorizer on the preprocessed answers\n",
    "    vectors = vectorizer.fit_transform([notes1, notes2])\n",
    "\n",
    "    # Compute the cosine similarity between the vectors\n",
    "    similarity = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def open_text_file():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Text Files\", \"*.txt\")])\n",
    "    if file_path:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        text_entry.delete(\"1.0\", tk.END)\n",
    "        text_entry.insert(tk.END, text)\n",
    "\n",
    "def open_pdf_file():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"PDF Files\", \"*.pdf\")])\n",
    "    if file_path:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text()\n",
    "        compare_entry.delete(\"1.0\", tk.END)\n",
    "        compare_entry.insert(tk.END, text)\n",
    "        \n",
    "def compare():\n",
    "    notes1 = text_entry.get(\"1.0\", tk.END)\n",
    "    notes2 = compare_entry.get(\"1.0\", tk.END)\n",
    "    similarity_score = compare_notes(notes1, notes2)\n",
    "    similarity_label.config(text=f\"Similarity score: {similarity_score:.2f}\")    \n",
    "    \n",
    "    \n",
    "# Create the main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Notes Comparison\")\n",
    "window.geometry(\"500x400\")\n",
    "\n",
    "\n",
    "style = ttk.Style()\n",
    "style.configure(\"TLabel\", foreground=\"#333\", font=(\"Arial\", 12))\n",
    "style.configure(\"TButton\", font=(\"Arial\", 12))\n",
    "style.configure(\"TText\", font=(\"Arial\", 12))\n",
    "\n",
    "# First Set of Notes\n",
    "text_label = ttk.Label(window, text=\"First Set of Notes:\")\n",
    "text_label.pack()\n",
    "\n",
    "text_entry = tk.Text(window, height=5)\n",
    "text_entry.pack(pady=5)\n",
    "\n",
    "open_text_button = ttk.Button(window, text=\"Open Text File\", command=open_text_file)\n",
    "open_text_button.pack()\n",
    "\n",
    "# Second Set of Notes\n",
    "compare_label = ttk.Label(window, text=\"Second Set of Notes:\")\n",
    "compare_label.pack()\n",
    "\n",
    "compare_entry = tk.Text(window, height=5)\n",
    "compare_entry.pack(pady=5)\n",
    "\n",
    "open_pdf_button = ttk.Button(window, text=\"Open PDF File\", command=open_pdf_file)\n",
    "open_pdf_button.pack()\n",
    "\n",
    "# Compare Button\n",
    "compare_button = ttk.Button(window, text=\"Compare Notes\", command=compare)\n",
    "compare_button.pack(pady=10)\n",
    "\n",
    "# Similarity Score\n",
    "similarity_label = ttk.Label(window, text=\"Similarity score: \")\n",
    "similarity_label.pack()\n",
    "\n",
    "# Run the main event loop\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5ec6769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fd9b222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2856a283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546c6a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
